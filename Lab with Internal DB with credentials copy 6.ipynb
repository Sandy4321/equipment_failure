{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Package installation", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "!pip install --upgrade watson-machine-learning-client --no-cache | tail -n 1\n!pip install --upgrade numpy --no-cache | tail -n 1\n!pip install --upgrade lime --no-cache | tail -n 1\n!pip install --upgrade SciPy --no-cache | tail -n 1", 
            "cell_type": "raw", 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "!pip install --upgrade watson-machine-learning-client --no-cache \n!pip install --upgrade numpy --no-cache \n!pip install --upgrade lime --no-cache \n!pip install --upgrade SciPy --no-cache ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "WML_CREDENTIALS = {\n  \"apikey\": \"haikTOuwibItbgRYtDwuTD1Nnht8bIN96LeoSHihp4Db\",\n  \"iam_apikey_description\": \"Auto generated apikey during resource-key operation for Instance - crn:v1:bluemix:public:pm-20:us-south:a/97deeb0b7e78431438a00a04f20580b7:8385ac85-436d-470e-8e67-54c492adb554::\",\n  \"iam_apikey_name\": \"auto-generated-apikey-d7945c16-a7df-479f-84e8-56a1ea40416b\",\n  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/97deeb0b7e78431438a00a04f20580b7::serviceid:ServiceId-c35b5b3e-030f-4cde-9edc-9f234768fe85\",\n  \"instance_id\": \"8385ac85-436d-470e-8e67-54c492adb554\",\n  \"password\": \"8726f331-3271-4456-b593-e90675da02aa\",\n  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n  \"username\": \"d7945c16-a7df-479f-84e8-56a1ea40416b\"\n}", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Load the training data from github", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\nimport types\nimport pandas as pd\nimport numpy as np\nfrom botocore.client import Config\nimport ibm_boto3", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\nimport types\nimport pandas as pd\nimport numpy as np\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_a6ce39d216194fb8a502a27492c8b085 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='v2Mo9It3k1mx1nBmyYNUC3v8yDLkVkacud6QufD3ppqf',\n    ibm_auth_endpoint=\"https://iam.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_a6ce39d216194fb8a502a27492c8b085.get_object(Bucket='equipmentfailuredemo-donotdelete-pr-ae2wrxuzdldzsf',Key='EQUIPMENT_FAILURE.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\npd_data = pd.read_csv(body)\npd_data.head()\n\n", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data.columns", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "tips_summed = pd_data.groupby(['EQUIPMENT_FAILURE'])['S1'].count()\ntips_summed\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data=pd_data.sort_values(by=['WELL_ID', 'DATE'], ascending=[True, False])\npd_data.reset_index(level=0, inplace=True)\n\npd_data.head(10)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_failure_thingy=pd_data[pd_data['EQUIPMENT_FAILURE'] == 1]\ndf_failure_thingy.head()\n\ndf_failure_thingy=df_failure_thingy[['DATE','WELL_ID']]\n\ndf_failure_thingy=df_failure_thingy.rename(index=str, columns={\"DATE\": \"FAILURE_DATE\"})\n\ndf_failure_thingy", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_failure_thingy.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_failure_thingy=df_failure_thingy.drop_duplicates(subset='WELL_ID')\ndf_failure_thingy.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data=pd_data.sort_values(by=['WELL_ID'], ascending=[True])\ndf_failure_thingy=df_failure_thingy.sort_values(by=['WELL_ID'], ascending=[True])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data =pd_data.merge(df_failure_thingy, on=['WELL_ID'], how='left')\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data=pd_data.sort_values(by=['WELL_ID', 'DATE'], ascending=[True, False])\n\npd_data['FAILURE_DATE'] = pd.to_datetime(pd_data['FAILURE_DATE'])\npd_data['DATE'] = pd.to_datetime(pd_data['DATE'])\npd_data['C'] = pd_data['FAILURE_DATE'] - pd_data['DATE']\n\npd_data['TIME_TO_FAILURE'] = pd_data['C'] / np.timedelta64(1, 'D')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data=pd_data.sort_values(by=['WELL_ID', 'DATE'], ascending=[True, False])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd.set_option('display.max_rows', 50000)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data['FAILURE_TARGET'] = np.where(((pd_data.TIME_TO_FAILURE <= 30) & ((pd_data.TIME_TO_FAILURE>=0))), 1, 0)\n\npd_data.head(10)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "tips_summed = pd_data.groupby(['WELL_ID'])['FAILURE_TARGET'].sum()\ntips_summed\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "tips_summed = pd_data.groupby(['FAILURE_TARGET'])['S1'].count()\ntips_summed", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "xxxx=pd_data[pd_data['WELL_ID'] ==100017]\n\nxxxx.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_well_id=pd_data.drop_duplicates(subset='WELL_ID')\npd_well_id=pd_well_id[['WELL_ID']]\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_well_id.head(5)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_well_id.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_well_id.head(100)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_well_id['wookie'] = (np.random.randint(0, 10000, pd_well_id.shape[0]))/10000", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_well_id['MODELING_GROUP'] = np.where(((pd_well_id.wookie <= 0.30)), 'VALIDATION', 'MODELING')\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data=pd_data.sort_values(by=['WELL_ID'], ascending=[True])\npd_well_id=pd_well_id.sort_values(by=['WELL_ID'], ascending=[True])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data =pd_data.merge(pd_well_id, on=['WELL_ID'], how='left')\n\npd_data.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data=pd_data.drop(columns=['FAILURE_REPAIR_COST', 'FAILURE_PRODUCTION_COST', 'MAINTENANCE_COST',\n       'MAINTENANCE_PRODUCTION_LOSS', 'wookie','C','FAILURE_DATE','TIME_TO_FAILURE'])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "pd_data.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_validation=pd_data[pd_data['MODELING_GROUP'] == 'VALIDATION']\n\n\ndf_validation=df_validation.drop(columns=['MODELING_GROUP'])\ndf_validation.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_modeling=pd_data[pd_data['MODELING_GROUP'] == 'MODELING']\n\ndf_modeling=df_modeling.drop(columns=['MODELING_GROUP','EQUIPMENT_FAILURE'])\ndf_modeling.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "training_features=df_modeling[['REGION_CLUSTER','MAINTENANCE_VENDOR','MANUFACTURER','WELL_GROUP','TIME_SINCE_MAINTENANCE', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7',\n       'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17',\n       'S18', 'S19', 'S20', 'S21', 'S22']]\n#validation_features=df_validation[['WELL_ID','DATE''REGION_CLUSTER','MAINTENANCE_VENDOR','MANUFACTURER','WELL_GROUP','TIME_SINCE_MAINTENANCE', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7',\n   #    'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17',\n    #   'S18', 'S19', 'S20', 'S21', 'S22']]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "training_target=df_modeling[['FAILURE_TARGET']]\n#validation_target=df_validation[['FAILURE_TARGET']]\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "!pip install --upgrade imblearn --no-cache | tail -n 1", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "!pip install imblearn --upgrade", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "!pip install numpy", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "import numpy.dual as dual", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "from imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import SMOTENC\nsm = SMOTE(random_state=12, ratio = 1.0)\nsmx = SMOTENC(random_state=12,  categorical_features=[0, 1, 2, 3])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "x_res, y_res = smx.fit_sample(training_features, training_target)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_x=pd.DataFrame(x_res)\n\ndf_x.columns = [\n'REGION_CLUSTER','MAINTENANCE_VENDOR','MANUFACTURER','WELL_GROUP','TIME_SINCE_MAINTENANCE', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7',\n       'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17',\n       'S18', 'S19', 'S20', 'S21', 'S22']\ndf_x.head()\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_x.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_y=pd.DataFrame(y_res)\ndf_y.columns = ['FAILURE_TARGET']\ndf_y.head()\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_y.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_y.mean(axis = 0) ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_modeling = pd.concat([df_y, df_x], axis=1)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "tips_summed = df_modeling.groupby(['REGION_CLUSTER'])['FAILURE_TARGET'].mean()\ntips_summed\n\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_modeling.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_modeling['wookie'] = (np.random.randint(0, 10000, df_modeling.shape[0]))/10000\ndf_modeling=df_modeling[df_modeling['wookie'] <0.40]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_modeling=df_modeling.drop(columns=['wookie'])\n\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_modeling.mean(axis = 0) ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_modelingx = spark.createDataFrame(df_modeling)\ndf_validationx=spark.createDataFrame(df_validation)\ndf_modelingx.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Explore data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df_modelingx.printSchema()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "print(\"Number of records: \" + str(df_modelingx.count()))", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Create a model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "spark_df = df_modelingx\n#(train_data, test_data) = spark_df.randomSplit([0.8, 0.2], 24)\n\ntrain_data=spark_df\n\nMODEL_NAME = \"Equipment Failure Model\"\nDEPLOYMENT_NAME = \"Equipment Failure Model\"\n\nprint(\"Number of records for training: \" + str(train_data.count()))\n#print(\"Number of records for evaluation: \" + str(test_data.count()))\n\nspark_df.printSchema()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml import Pipeline, Model\nfrom pyspark.ml import linalg\n\n", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "si_REGION_CLUSTER = StringIndexer(inputCol = 'REGION_CLUSTER', outputCol = 'REGION_CLUSTER_IX')\nsi_MAINTENANCE_VENDOR = StringIndexer(inputCol = 'MAINTENANCE_VENDOR', outputCol = 'MAINTENANCE_VENDOR_IX')\nsi_MANUFACTURER = StringIndexer(inputCol = 'MANUFACTURER', outputCol = 'MANUFACTURER_IX')\nsi_WELL_GROUP = StringIndexer(inputCol = 'WELL_GROUP', outputCol = 'WELL_GROUP_IX')\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "si_Label = StringIndexer(inputCol=\"FAILURE_TARGET\", outputCol=\"label\").fit(train_data)\nlabel_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=si_Label.labels)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "va_features = VectorAssembler(inputCols=['REGION_CLUSTER_IX', 'MAINTENANCE_VENDOR_IX',\n       'MANUFACTURER_IX', 'WELL_GROUP_IX', 'TIME_SINCE_MAINTENANCE', 'S1', 'S2',\n       'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13',\n       'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20', 'S21', 'S22'], outputCol=\"features\")", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "from pyspark.ml.classification import RandomForestClassifier\nclassifier = RandomForestClassifier(featuresCol=\"features\")\nfrom pyspark.ml.classification import GBTClassifier\n#classifier = GBTClassifier(featuresCol=\"features\")\n\npipeline = Pipeline(stages=[ si_Label, si_REGION_CLUSTER, si_MAINTENANCE_VENDOR, si_MANUFACTURER, si_WELL_GROUP, va_features, classifier, label_converter])\nmodel = pipeline.fit(train_data)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "predictions = model.transform(train_data)\nevaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\narea_under_curve = evaluatorDT.evaluate(predictions)\n\n#default evaluation is areaUnderROC\nprint(\"areaUnderROC = %g\" % area_under_curve)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "predictions = model.transform(test_data)\nevaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\narea_under_curve = evaluatorDT.evaluate(predictions)\n\n#default evaluation is areaUnderROC\nprint(\"areaUnderROC = %g\" % area_under_curve)", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "source": "predictions = model.transform(df_validationx)\nevaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\narea_under_curve = evaluatorDT.evaluate(predictions)\n\n#default evaluation is areaUnderROC\nprint(\"areaUnderROC = %g\" % area_under_curve)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "predictions.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output=predictions.toPandas() ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output.columns", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output=df_output.sort_values(by=['WELL_ID', 'DATE'], ascending=[True, False])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df=df_output\ndf.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df['FLIPPER'] = np.where(((df.WELL_ID.eq(df.WELL_ID.shift()))), 0,1 )", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df['DINGDONG'] = np.where(((df.FLIPPER==0) & (df.EQUIPMENT_FAILURE==0)), 0,1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "wookie=df[['index', 'WELL_ID', 'DATE', 'EQUIPMENT_FAILURE', 'FAILURE_TARGET', 'label', 'REGION_CLUSTER_IX',\n       'MAINTENANCE_VENDOR_IX', 'MANUFACTURER_IX', 'WELL_GROUP_IX', 'features',\n       'rawPrediction', 'probability', 'prediction', 'predictedLabel','FLIPPER','DINGDONG']]\n\n\n\nwookie.head(1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df['cumsum'] = df['predictedLabel'].cumsum()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df['bootie']=1\ndf['dingle']= df.groupby(['cumsum'])['bootie'].cumsum()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "wookie=df[['index', 'WELL_ID', 'DATE', 'EQUIPMENT_FAILURE', 'FAILURE_TARGET', 'label', 'REGION_CLUSTER_IX',\n       'MAINTENANCE_VENDOR_IX', 'MANUFACTURER_IX', 'WELL_GROUP_IX', 'features',\n       'rawPrediction', 'probability', 'prediction', 'predictedLabel','FLIPPER','DINGDONG','cumsum','bootie','dingle']]\n\n\n\nwookie.head(1000)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "dater=df[['DATE']]\ndater.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "dater=dater.drop_duplicates(subset='DATE')\ndater.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "dater['DATE_KEY'] = np.arange(len(dater))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df['FLIPPER'] = np.where(((df.WELL_ID.eq(df.WELL_ID.shift()))), 0,1 )", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "dater=dater.sort_values(by=['DATE'], ascending=[True])\n#dater.reindex(level=1, inplace=False)\ndater['COUNTER']=dater['DATE_KEY']\ndater=dater.set_index('COUNTER')\ndater.head(1)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df =df.merge(dater, on=['DATE'], how='left')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df['FLIPPER'] = np.where(((df.WELL_ID.eq(df.WELL_ID.shift()))), 0,1 )", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df=df[['WELL_ID', 'DATE', 'EQUIPMENT_FAILURE',\n       'rawPrediction', 'probability', 'prediction', 'predictedLabel', 'C',\n       'DATE_KEY','FLIPPER']]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df.head(10000)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df.loc[0, 'C'] = df.loc[0, 'index']", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "for i in range(1, len(df)):\n    df.loc[i, 'C'] = df.loc[i-1, 'C']+1", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output['match'] = df_output.WELL_ID.eq(df_output.WELL_ID.shift())", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output['FLIPPER'] = np.where(((df_output.WELL_ID.eq(df_output.WELL_ID.shift()))), 0,1 )", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output['THECOUNTER'] = np.where((df_output.FLIPPER==1), 0,df_output.THECOUNTER.shift()+1 )", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output=df_output.sort_values(by=['WELL_ID'], ascending=[True])\ndf_output.reset_index(level=1, inplace=True)\n\ndf_output.head(10)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_failure_actual=df_output[df_output['EQUIPMENT_FAILURE'] == 1]\n\n\ndf_failure_actual=df_failure_actual[['DATE','WELL_ID']]\n\ndf_failure_actual=df_failure_actual.rename(index=str, columns={\"DATE\": \"FAILURE_DATE\"})\ndf_failure_actual.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\ndf_failure_actual=df_failure_actual.drop_duplicates(subset='WELL_ID')\ndf_failure_actual.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output =df_output.merge(df_failure_actual, on=['WELL_ID'], how='left')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "import datetime as dt     \ndf_output['TODAY'] =pd.to_datetime('now')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\ndf_output['P_FAIL_DATE'] = np.where(((df_output.predictedLabel == '1')), df_output.DATE,df_output.TODAY )", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output=df_output.sort_values(by=['WELL_ID', 'DATE'], ascending=[True, False])\n\ndf_output['FAILURE_DATE'] = pd.to_datetime(df_output['FAILURE_DATE'])\ndf_output['P_FAIL_DATE'] = pd.to_datetime(df_output['P_FAIL_DATE'])\ndf_output['C'] = df_output['FAILURE_DATE'] - df_output['P_FAIL_DATE']\n\ndf_output['WARNING_DAYS'] = df_output['C'] / np.timedelta64(1, 'D')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output['TRUE_POSITIVE_W'] = np.where(((df_output.WARNING_DAYS <= 90) & ((df_output.WARNING_DAYS>=0)) & ((df_output.predictedLabel == '1'))), 1, 0)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "true_positive=df_output[df_output['predictedLabel'] == '1']\ntrue_positive=true_positive[['WELL_ID','WARNING_DAYS','FAILURE_DATE']]\n\ntrue_positive=true_positive[true_positive['WARNING_DAYS'] >= 0]\ntrue_positive=true_positive[true_positive['WARNING_DAYS'] <=90 ]\n\ntrue_positive['EQUIPMENT_FAILURE']=1\ntrue_positive['TRUE_POSITIVE']=1\n\ntrue_positive.head(4)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "true_positive=true_positive.drop_duplicates(subset='WELL_ID', keep='last')\ntrue_positive", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output=df_output[['index', 'WELL_ID', 'DATE', 'REGION_CLUSTER', 'MAINTENANCE_VENDOR',\n       'MANUFACTURER', 'WELL_GROUP', 'TIME_SINCE_MAINTENANCE', 'S1', 'S2',\n       'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13',\n       'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20', 'S21', 'S22',\n       'EQUIPMENT_FAILURE', 'FAILURE_TARGET', 'label', 'REGION_CLUSTER_IX',\n       'MAINTENANCE_VENDOR_IX', 'MANUFACTURER_IX', 'WELL_GROUP_IX', 'features',\n       'rawPrediction', 'probability', 'prediction', 'predictedLabel',\n       'FAILURE_DATE', 'TODAY', 'P_FAIL_DATE', 'TRUE_POSITIVE_W']]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output=df_output.sort_values(by=['WELL_ID'], ascending=[True])\ntrue_positive=true_positive.sort_values(by=['WELL_ID'], ascending=[True])\ndf_output =df_output.merge(true_positive, on=['WELL_ID'], how='left')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output['TRUE_POSITIVE'] = np.where(((df_output.WARNING_DAYS <= 90) & ((df_output.WARNING_DAYS>=0)) & ((df_output.predictedLabel == '1'))), 1, 0)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output[df_output['EQUIPMENT_FAILURE'] == 1]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "xxx=df_output[df_output['WELL_ID'] == 100001]\npd.set_option('display.max_rows', 50000)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "xxx=xxx[['index', 'WELL_ID', 'DATE', \n       'EQUIPMENT_FAILURE', 'FAILURE_TARGET', 'label', \n       'rawPrediction', 'probability', 'prediction', 'predictedLabel', 'TODAY',\n       'P_FAIL_DATE', 'FAILURE_DATE', 'C', 'WARNING_DAYS', 'TRUE_POSITIVE']]\n\nxxx", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "tips_summed = df_output.groupby(['label','predictedLabel'])['S1'].count()\ntips_summed", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_confusion = pd.crosstab(df_output['EQUIPMENT_FAILURE'], df_output['prediction'])\ndf_confusion", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output['y']= (df_output['probability'])\ndf_output['phat'] = df_output.y.str.slice(start=1, stop=2, step=None)\ndf_output['phat'] = df_output['phat'].astype(float)\ndf_output=df_output.drop(columns=['y'])\ndf_output", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\n\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "z=(pd.qcut(df_output['S1'], 4, labels=False, retbins=True, precision=3, duplicates='raise'))\nz=pd.DataFrame(z)\nz\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df_output.groupby(pd.qcut(df_output.S1, 10))['predictedLabel'].mean()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Save and deploy the model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "from scipy import sparse\nfrom scipy import linalg", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient \nimport json \n\n\n\nwml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "### Remove existing model and deployment", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "model_deployment_ids = wml_client.deployments.get_uids()\nfor deployment_id in model_deployment_ids:\n    deployment = wml_client.deployments.get_details(deployment_id)\n    model_id = deployment['entity']['deployable_asset']['guid']\n    if deployment['entity']['name'] == DEPLOYMENT_NAME:\n        print('Deleting deployment id', deployment_id)\n        wml_client.deployments.delete(deployment_id)\n        print('Deleting model id', model_id)\n        wml_client.repository.delete(model_id)\nwml_client.repository.list_models()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "model_props = {\n    wml_client.repository.ModelMetaNames.NAME: \"{}\".format(MODEL_NAME),\n    wml_client.repository.ModelMetaNames.EVALUATION_METHOD: \"binary\",\n    wml_client.repository.ModelMetaNames.EVALUATION_METRICS: [\n        {\n           \"name\": \"areaUnderROC\",\n           \"value\": area_under_curve,\n           \"threshold\": 0.85\n        }\n    ]\n}", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "wml_models = wml_client.repository.get_details()\nmodel_uid = None\nfor model_in in wml_models['models']['resources']:\n    if MODEL_NAME == model_in['entity']['name']:\n        model_uid = model_in['metadata']['guid']\n        break\n\nif model_uid is None:\n    print(\"Storing model ...\")\n\n    published_model_details = wml_client.repository.store_model(model=model, meta_props=model_props, training_data=train_data, pipeline=pipeline)\n    model_uid = wml_client.repository.get_model_uid(published_model_details)\n    print(\"Done\")", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "model_uid", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "wml_deployments = wml_client.deployments.get_details()\ndeployment_uid = None\nfor deployment in wml_deployments['resources']:\n    if DEPLOYMENT_NAME == deployment['entity']['name']:\n        deployment_uid = deployment['metadata']['guid']\n        break\n\nif deployment_uid is None:\n    print(\"Deploying model...\")\n\n    deployment = wml_client.deployments.create(artifact_uid=model_uid, name=DEPLOYMENT_NAME, asynchronous=False)\n    deployment_uid = wml_client.deployments.get_uid(deployment)\n    \nprint(\"Model id: {}\".format(model_uid))\nprint(\"Deployment id: {}\".format(deployment_uid))", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Configure OpenScale", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from ibm_ai_openscale import APIClient\nfrom ibm_ai_openscale.engines import *\nfrom ibm_ai_openscale.utils import *\nfrom ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\nfrom ibm_ai_openscale.supporting_classes.enums import *", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "### Get AI OpenScale GUID", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import requests\n\nAIOS_GUID = None\ntoken_data = {\n    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n    'response_type': 'cloud_iam',\n    'apikey': CLOUD_API_KEY\n}\n\nresponse = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\niam_token = response.json()['access_token']\niam_headers = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer %s' % iam_token\n}\n\nresources = json.loads(requests.get('https://resource-controller.cloud.ibm.com/v2/resource_instances', headers=iam_headers).text)['resources']\nfor resource in resources:\n    if \"aiopenscale\" in resource['id'].lower():\n        AIOS_GUID = resource['guid']\n        \nAIOS_CREDENTIALS = {\n    \"instance_guid\": AIOS_GUID,\n    \"apikey\": CLOUD_API_KEY,\n    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n}\n\nif AIOS_GUID is None:\n    print('AI OpenScale GUID NOT FOUND')\nelse:\n    print(AIOS_GUID)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Create schema and datamart", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "ai_client = APIClient(aios_credentials=AIOS_CREDENTIALS)\nai_client.version\ntime.sleep(20)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "### Set up datamart", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "try:\n    data_mart_details = ai_client.data_mart.get_details()\n    if 'internal_database' in data_mart_details and data_mart_details['internal_database']:\n        if KEEP_MY_INTERNAL_POSTGRES:\n            print('Using existing internal datamart.')\n        else:\n            if DB_CREDENTIALS is None:\n                print('No postgres credentials supplied. Using existing internal datamart')\n            else:\n                print('Switching to external datamart')\n                ai_client.data_mart.delete(force=True)\n                ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n    else:\n        print('Using existing external datamart')\nexcept:\n    if DB_CREDENTIALS is None:\n        print('Setting up internal datamart')\n        ai_client.data_mart.setup(internal_db=True)\n    else:\n        print('Setting up external datamart')\n        ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n    ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "data_mart_details = ai_client.data_mart.get_details()\ndata_mart_details", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Bind machine learning engines", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "binding_uid = ai_client.data_mart.bindings.add('WML instance', WatsonMachineLearningInstance(WML_CREDENTIALS))\nif binding_uid is None:\n    binding_uid = ai_client.data_mart.bindings.get_details()['service_bindings'][0]['metadata']['guid']\nbindings_details = ai_client.data_mart.bindings.get_details()\nai_client.data_mart.bindings.list()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "print(binding_uid)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "ai_client.data_mart.bindings.list_assets()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Subscriptions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Remove existing  subscriptions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\nfor subscription in subscriptions_uids:\n    sub_name = ai_client.data_mart.subscriptions.get_details(subscription)['entity']['asset']['name']\n    if sub_name == MODEL_NAME:\n        ai_client.data_mart.subscriptions.delete(subscription)\n        print('Deleted existing subscription for', MODEL_NAME)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n    model_uid,\n    problem_type=ProblemType.BINARY_CLASSIFICATION,\n    input_data_type=InputDataType.STRUCTURED,\n    label_column='BAD_YIELD',\n    prediction_column='predictedLabel',\n    probability_column='probability',\n    feature_columns = ['WS_001_FLOW_MEAN', 'WS_001_FLOW_MIN', 'WS_001_FLOW_MAX',\n       'WS_001_CONC_MEAN', 'WS_001_CONC_MIN', 'WS_001_CONC_MAX',\n       'DMW_FLOW_MEAN', 'DMW_FLOW_MIN', 'DMW_FLOW_MAX', 'ALK_FLOW_MEAN',\n       'ALK_FLOW_MIN', 'ALK_FLOW_MAX', 'RPM_MEAN', 'RPM_MIN', 'RPM_MAX','PLANT_A'],\n    categorical_columns = ['PLANT_A']\n))\n\nif subscription is None:\n    print('Subscription already exists; get the existing one')\n    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n    for sub in subscriptions_uids:\n        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n            subscription = ai_client.data_mart.subscriptions.get(sub)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Get subscription list", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\nai_client.data_mart.subscriptions.list()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\nsubscription.get_details()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "### Score the model so we can configure monitors", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "propensity_to_buy_scoring_endpoint = None\nprint(deployment_uid)\n\nfor deployment in wml_client.deployments.get_details()['resources']:\n    if deployment_uid in deployment['metadata']['guid']:\n        propensity_to_buy_scoring_endpoint = deployment['entity']['scoring_url']\n        \nprint(propensity_to_buy_scoring_endpoint)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "fields = ['WS_001_FLOW_MEAN', 'WS_001_FLOW_MIN', 'WS_001_FLOW_MAX',\n       'WS_001_CONC_MEAN', 'WS_001_CONC_MIN', 'WS_001_CONC_MAX',\n       'DMW_FLOW_MEAN', 'DMW_FLOW_MIN', 'DMW_FLOW_MAX', 'ALK_FLOW_MEAN',\n       'ALK_FLOW_MIN', 'ALK_FLOW_MAX', 'RPM_MEAN', 'RPM_MIN', 'RPM_MAX', 'PLANT_A']\nvalues = [[91.472265,91.591823,91.400894,29.999306,29.9453,30.0347,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5010.304375,5010.05,5010.61,1],\n          [91.286568,91.333725,91.225539,29.999756,29.8993,30.1047,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5011.043681,5010.74,5011.32,1],\n          [91.581607,91.677855,91.57625,30.000624,29.9481,30.0648,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5008.680625,5007.45,5009.42,0],\n          [91.332992,91.419757,91.313216,30.000023,29.9221,30.1148,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5010.7575,5010.47,5011.09,1],\n          [87.178007,87.376229,87.19236,65.001133,64.8447,65.1378,92.93055,92.934958,92.91834,87.957784,88.105276,87.929657,5009.978056,5009.61,5010.3,1],\n          [91.463103,91.591823,91.400894,29.999842,29.9367,30.0449,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5010.263889,5009.75,5010.5,0],\n          [87.284294,87.462261,87.280037,65.000094,64.9171,65.0708,92.93055,92.934958,92.91834,87.957784,88.105276,87.929657,5008.015347,5006.6,5009.73,1],\n          [87.121198,87.290196,87.104682,65.000774,64.8889,65.1762,92.93055,92.934958,92.91834,86.453545,86.63842,86.425383,5009.210625,5008.67,5009.67,1],\n          [87.2452,87.462261,87.19236,62.999506,62.8072,63.167,92.682929,92.68715,92.67134,87.957784,88.105276,87.929657,5011.408889,5011.12,5011.59,0],\n          [87.099207,87.032099,87.280037,64.983894,62.8779,65.1535,92.93055,92.934958,92.91834,86.453545,86.63842,86.425383,5010.101181,5009.21,5010.83,0],\n          [91.243197,91.333725,91.225539,29.998703,29.9305,30.1019,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5010.714444,5010.44,5011.11,1],\n          [91.612149,91.677855,91.57625,29.998469,29.9674,30.0269,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5009.607431,5008.38,5010.55,1],\n          [87.005748,87.204164,86.929326,65.001815,64.1377,65.9022,92.93055,92.934958,92.91834,86.453545,86.63842,86.425383,5010.824861,5010.53,5011.05,1],\n          [91.260301,91.333725,91.225539,30.000992,29.9268,30.0831,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5010.054444,5009.72,5010.31,1],\n          [90.70443,90.731497,90.699472,29.513889,29.0,30.0,88.597187,88.598325,88.595852,90.464848,90.550036,90.43678,5007.784861,5006.61,5008.85,1],\n          [91.538237,91.677855,91.488572,30.000409,29.9454,30.0518,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5009.791319,5008.99,5010.11,1],\n          [87.051561,87.204164,87.017004,64.999602,64.8108,65.146,92.93055,92.934958,92.91834,86.453545,86.63842,86.425383,5009.726389,5005.68,5010.44,0],\n          [91.614593,91.763888,91.57625,29.999788,29.9509,30.0482,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,5008.214444,5006.21,5009.69,0],\n          [91.365367,91.419757,91.313216,30.00108,29.8762,30.1167,88.597187,88.598325,88.595852,91.467674,91.52794,91.439629,4998.986875,4996.14,5003.11,0]\n         ]\npayload_scoring = {\"fields\": fields,\"values\": values}\nscoring_response = wml_client.deployments.score(propensity_to_buy_scoring_endpoint, payload_scoring)\n\nprint(scoring_response)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Quality and feedback monitoring", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Enable quality monitoring", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Wait ten seconds to allow the payload logging table to be set up before we begin enabling monitors.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "time.sleep(20)\nsubscription.quality_monitoring.enable(threshold=0.7, min_records=100)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "### Feedback logging", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!rm df_feedback.json\n!wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/df_feedback.json", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "with open('df_feedback.json') as feedback_file:\n    df_feedback = json.load(feedback_file)\nsubscription.feedback_logging.store(df_feedback)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "subscription.feedback_logging.show_table()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "run_details = subscription.quality_monitoring.run()\nstatus = run_details['status']\nid = run_details['id']\nprint(id)\n\nprint(\"Run status: {}\".format(status))\n\nstart_time = time.time()\nelapsed_time = 0\n\nwhile status != 'completed' and elapsed_time < 60:\n    time.sleep(10)\n    run_details = subscription.quality_monitoring.get_run_details(run_uid=id)\n    status = run_details['status']\n    elapsed_time = time.time() - start_time\n    print(\"Run status: {}\".format(status))", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "subscription.quality_monitoring.get_run_details()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "subscription.quality_monitoring.show_table()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "subscription.quality_monitoring._get_data_from_rest_api()", 
            "cell_type": "markdown", 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "ai_client.data_mart.get_deployment_metrics()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Fairness monitoring", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "subscription.fairness_monitoring.enable(\n            features=[\n                Feature(\"PLANT_A\", majority=[[1,1]], minority=[[0,0]], threshold=0.95)\n            ],\n            favourable_classes=['GOOD'],\n            unfavourable_classes=['BAD'],\n            min_records=1000,\n            training_data=df_training\n        )", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Score the model again now that monitoring is configured", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!rm df_payload_biased.json\n!wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/df_payload_biased.json", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Score 1000 randomly chosen records", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import random\n\nwith open('df_payload_biased.json', 'r') as scoring_file:\n    scoring_data = json.load(scoring_file)\n\nfields = scoring_data['fields']\nvalues = []\nfor _ in range(1000):\n    values.append(random.choice(scoring_data['values']))\npayload_scoring = {\"fields\": fields, \"values\": values}\n\nscoring_response = wml_client.deployments.score(propensity_to_buy_scoring_endpoint, payload_scoring)\nprint(scoring_response)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "subscription.get_details()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Insert historical payloads", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!rm payload_history*.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_1.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_2.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_3.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_4.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_5.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_6.json\n!wget https://raw.githubusercontent.com/shadgriffin/propensitytobuylab/master/payload_history_7.json", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "historyDays = 7\nfrom ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\nimport datetime\nimport time", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\n\nfor day in range(historyDays):\n    print('Loading day {}'.format(day + 1))\n    history_file = 'payload_history_' + str(day + 1) + '.json'\n    with open(history_file) as f:\n        payloads = json.load(f)\n        hourly_records = int(len(payloads) / 24)\n        index = 0\n        for hour in range(24):\n            recordsList = []\n            for i in range(hourly_records):\n                score_time = str(datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1))))\n                recordsList.append(PayloadRecord(request=payloads[index]['request'], response=payloads[index]['response'], scoring_timestamp=score_time))\n                index += 1\n            subscription.payload_logging.store(records=recordsList)\nprint('Finished')", 
            "cell_type": "raw", 
            "metadata": {
                "scrolled": true
            }
        }, 
        {
            "source": "data_mart_id = subscription.get_details()['metadata']['url'].split('/service_bindings')[0].split('marts/')[1]\nprint(data_mart_id)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "performance_metrics_url = 'https://api.aiopenscale.cloud.ibm.com' + subscription.get_details()['metadata']['url'].split('/service_bindings')[0] + '/metrics'\nprint(performance_metrics_url)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Insert historical fairness metrics", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!rm fairness_records.json\n!wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/fairness_records.json\nimport random", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "\ntoken_data = {\n    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n    'response_type': 'cloud_iam',\n    'apikey': AIOS_CREDENTIALS['apikey']\n}\n\nresponse = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\niam_token = response.json()['access_token']\niam_headers = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer %s' % iam_token\n}\n\nwith open('fairness_records.json', 'r') as history_file:\n    payloads = json.load(history_file)\n\nfor day in range(historyDays):\n    print('Day', day + 1)\n    for hour in range(24):\n        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n        \n        qualityMetric = {\n            'metric_type': 'fairness',\n            'binding_id': binding_uid,\n            'timestamp': score_time,\n            'subscription_id': model_uid,\n            'asset_revision': model_uid,\n            'deployment_id': deployment_uid,\n            'value': random.choice(payloads)\n        }\n\n        response = requests.post(performance_metrics_url, json=[qualityMetric], headers=iam_headers)\nprint('Finished')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Insert historical quality metrics", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "token_data = {\n    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n    'response_type': 'cloud_iam',\n    'apikey': AIOS_CREDENTIALS['apikey']\n}\n\nresponse = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\niam_token = response.json()['access_token']\niam_headers = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer %s' % iam_token\n}\n\nmeasurements = [0.94, 0.91, 0.78, 0.82, 0.90, 0.94, 0.93]\nfor day in range(historyDays):\n    print('Day', day + 1)\n    for hour in range(24):\n        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n        \n        qualityMetric = {\n            'metric_type': 'quality',\n            'binding_id': binding_uid,\n            'timestamp': score_time,\n            'subscription_id': model_uid,\n            'asset_revision': model_uid,\n            'deployment_id': deployment_uid,\n            'value': {\n                'quality': measurements[day],\n                'threshold': 0.85,\n                'metrics': [\n                    {\n                        'name': 'auroc',\n                        'value': measurements[day],\n                        'threshold': 0.75\n                    }\n                ]\n            }\n        }\n\n        response = requests.post(performance_metrics_url, json=[qualityMetric], headers=iam_headers)\nprint('Finished')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Insert historical performance metrics", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "token_data = {\n    'grant_type': 'urn:ibm:params:oauth:grant-type:apikey',\n    'response_type': 'cloud_iam',\n    'apikey': AIOS_CREDENTIALS['apikey']\n}\n\nresponse = requests.post('https://iam.bluemix.net/identity/token', data=token_data)\niam_token = response.json()['access_token']\niam_headers = {\n    'Content-Type': 'application/json',\n    'Authorization': 'Bearer %s' % iam_token\n}\n\nfor day in range(historyDays):\n    print('Day', day + 1)\n    for hour in range(24):\n        score_time = (datetime.datetime.utcnow() + datetime.timedelta(hours=(-(24*day + hour + 1)))).strftime('%Y-%m-%dT%H:%M:%SZ')\n        score_count = random.randint(600, 6000)\n        score_resp = random.uniform(600, 3000)\n\n        performanceMetric = {\n            'metric_type': 'performance',\n            'binding_id': binding_uid,\n            'timestamp': score_time,\n            'subscription_id': model_uid,\n            'asset_revision': model_uid,\n            'deployment_id': deployment_uid,\n            'value': {\n                'response_time': score_resp,\n                'records': score_count\n            }\n        }\n\n        response = requests.post(performance_metrics_url, json=[performanceMetric], headers=iam_headers)\nprint('Finished')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Configure Explainability", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "pd_data.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "from ibm_ai_openscale.supporting_classes import *\nsubscription.explainability.enable(training_data=df_training)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "subscription.explainability.get_details()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Run fairness monitor", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Kick off a fairness monitor run on current data. Depending on how fast the monitor runs, the table may not contain the most recent results.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "run_details = subscription.fairness_monitoring.run()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "subscription.fairness_monitoring.show_table()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Additional data to help debugging", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#print('Datamart:', data_mart_id)\nprint('Model:', model_uid)\nprint('Deployment:', deployment_uid)\nprint('Binding:', binding_uid)\nprint('Scoring URL:', propensity_to_buy_scoring_endpoint)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Identify transactions for Explainability", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Transaction IDs identified by the cells below can be copied and pasted into the Explainability tab of the OpenScale dashboard.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import json, random\n\nDEPLOYMENT_NAME = \"Yield Model\"\nMIN_RECORDS = 1000\nMAX_RECORDS = 1000", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "!rm df_payload_biased.json\n!wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/df_payload_biased.json", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "wml_deployments = wml_client.deployments.get_details()\nscoring_url = None\nfor deployment in wml_deployments['resources']:\n    if DEPLOYMENT_NAME == deployment['entity']['name']:\n        scoring_url = deployment['entity']['scoring_url']\n        break\n    \nprint(\"Scoring URL: {}\".format(scoring_url))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "try:\n    with open('df_payload_biased.json', 'r') as scoring_file:\n        scoring_data = json.load(scoring_file)\n    print('file found')\n    \nexcept:\n    !wget https://raw.githubusercontent.com/shadgriffin/oglabworking/master/df_payload_biased.json\n    with open('df_payload_biased.json', 'r') as scoring_file:\n        scoring_data = json.load(scoring_file)\n    print('file downloaded')\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "fields = scoring_data['fields']\nvalues = []\nfor _ in range(0, random.randint(MIN_RECORDS, MAX_RECORDS)):\n    values.append(random.choice(scoring_data['values']))\npayload_scoring = {\"fields\": fields, \"values\": values}\n\nscoring_response = wml_client.deployments.score(scoring_url, payload_scoring)\nprint(scoring_response)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "time.sleep(10)\npayload_data = subscription.payload_logging.get_table_content(limit=200)\npayload_data.filter(items=['scoring_id', 'predictedLabel', 'probability','PLANT_A'])", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Congratulations!\n\nYou have finished the hands-on lab for IBM Watson OpenScale. You can now view the [OpenScale Dashboard](https://aiopenscale.cloud.ibm.com/). Click on the tile for the Propensity to Buy model to see fairness, accuracy, and performance monitors. Click on the timeseries graph to get detailed information on transactions during a specific time window.\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark", 
            "name": "python36", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}